# Visualization of predicted results

PaddleX provides a series of visualization functions for model prediction and result analysis.

## paddlex.det.visualize
> **Visualization of prediction results for object detection/instance segmentation**
```
paddlex.det.visualize(image, result, threshold=0.5, save_dir='. /', color=None)
```
Visualize a box and mask predicted by object detection/instance segmentation models in the original figure.

### Parameters
> * **image** (str|np.ndarray): File path or numpy array of the original figure (HWC arrangement, BGR format).
> * **result** (str): Model prediction results.
> * **threshold**(float): Score threshold. Any box of which the confidence is smaller than this threshold is filtered and is not visualized. It is 0.5 by default.
> * **save_dir**(str): Path where visualized results are saved. If this parameter is None, it indicates that the path does not exist and that this function returns visualized results in the form of np.ndarray. If this parameter is set to a directory path, this function saves visualized results in this directory. It is '. /' by default.
> * **color**(list|tuple|np.array): List of BGR color values of all categories, shape of the list is required to be `Nx3` where `N` is the number of categories and color value should be within [0, 255] range. If set as None, the color values are generated automatically. Default: None.

### Usage Example
> Click to download the [model](https://bj.bcebos.com/paddlex/models/xiaoduxiong_epoch_12.tar.gz) in the following example
```
import paddlex as pdx
model = pdx.load_model('xiaoduxiong_epoch_12')
result = model.predict('./xiaoduxiong_epoch_12/xiaoduxiong.jpeg')
pdx.det.visualize('./xiaoduxiong_epoch_12/xiaoduxiong.jpeg', result, save_dir='./')
# Prediction results are saved in . /visualize_xiaoduxiong.jpeg
```
## paddlex.seg.visualize
> **Visualization of prediction results for semantic segmentation models**
```
paddlex.seg.visualize(image, result, weight=0.6, save_dir='. /', color=None)
```
Visualize a mask predicted by semantic segmentation models in the original figure.

### Parameters
> * **image** (str|np.ndarray): File path or numpy array of the original figure (HWC arrangement, BGR format).
> * **result** (str): Model prediction results.
> * **weight**(float): Weight factor of mask visualized results and the original figure. The weight parameter indicates a weight of the original figure. It is 0.6 by default.
> * **save_dir**(str): Path where visualized results are saved. If this parameter is None, it indicates that the path does not exist and that this function returns visualized results in the form of np.ndarray. If this parameter is set to a directory path, this function saves visualized results in this directory. It is '. /' by default.
> * **color** (list): List of all classes of BGR color values. For example, it can be set to 255, 255, 255, 0, 0, 0[ in the case of two classes]. It is None by default, indicating that the list of colors generated by default is used.


### Usage example
> Click to download the [model](https://bj.bcebos.com/paddlex/models/cityscape_deeplab.tar.gz) and [test image](https://bj.bcebos.com/paddlex/datasets/city.png) in the following example
```
import paddlex as pdx
model = pdx.load_model('cityscape_deeplab')
result = model.predict('city.png')
pdx.det.visualize('city.png', result, save_dir='./')
 # Prediction results are saved in . /visualize_city.png
```

## paddlex.det.draw_pr_curve
> **Visualization of accuracy rate versus recall rate for object detection/instance segmentation**
```
paddlex.det. draw_pr_curve(eval_details_file=None, gt=None, pred_bbox=None, pred_mask=None, iou_thresh=0.5, save_dir='. /')
```
Visualize the relation of accuracy rate versus recall rate of each class in the evaluation results of the object detection/instance segmentation model as well as the relation of recall rate versus confidence threshold.
> Note: The `eval_result. json` file is contained in any model directory saved by PaddleX during training. This file path is passed to the `eval_details_file` parameter. A PR curve graph of the corresponding model on the validation set can be obtained by setting `iou_threshold`.

### Parameters
> * **eval_details_file** (str): Path where model evaluation results including true value information and prediction results are saved. It is None by default.
> * **gt** (list): True value information of the dataset. It is None by default.
> * **pred_bbox** (list): Predicted box by the model on the dataset. It is None by default.
> * **pred_mask** (list): Predicted mask by the model on the dataset. It is None by default.
> * **iou_thresh** (float): IoU threshold when the predicted box or mask is determined to be genuine yang. It is 0.5 by default.
> * **save_dir**(str): Path where visualized results are saved. It is '. /' by default.


**Note: **`eval_details_file` has a higher priority. True value information and prediction results are extracted from `eval_details_file` for analysis as long as `eval_details_file` is not None. When `eval_details_file` is None, `gt`, `pred_mask` and `pred_mask` are used to make an analysis.

### Usage example
Click to download the [model](https://bj.bcebos.com/paddlex/models/insect_epoch_270.zip) and [dataset](https://bj.bcebos.com/paddlex/datasets/insect_det.tar.gz) in the following example

> Method 1: Analyze an evaluation result file saved in the model folder during training, e .g. `eval_details.json` in the model (https://bj.bcebos.com/paddlex/models/insect_epoch_270.zip).
```
import paddlex as pdx
eval_details_file = 'insect_epoch_270/eval_details.json'
pdx.det.draw_pr_curve(eval_details_file, save_dir='./insect')
```
> Method 2: Analyze evaluation results returned by the model evaluation function.

```
import os
# Choose to use Card 0
os.environ['CUDA_VISIBLE_DEVICES'] = '0'

from paddlex.det import transforms
import paddlex as pdx

model = pdx.load_model('insect_epoch_270')
eval_dataset = pdx.datasets.VOCDetection(
    data_dir='insect_det',
    file_list='insect_det/val_list.txt',
    label_list='insect_det/labels.txt',
    transforms=model.eval_transforms)
metrics, evaluate_details = model.evaluate(eval_dataset, batch_size=8, return_details=True)
gt = evaluate_details['gt']
bbox = evaluate_details['bbox']
pdx.det.draw_pr_curve(gt=gt, pred_bbox=bbox, save_dir='./insect')
```

Relations of accuracy rate versus recall rate and recall rate versus confidence threshold of each class of the predicted box are visualized as follows:
![](./images/insect_bbox_pr_curve(iou-0.5).png)


## paddlex.slim.visualzie
> **Visualization analysis of model pruning proportions**
```
paddlex.slim.visualize(model, sensitivities_file, save_dir='. /')
```
Model pruning proportions can be analyzed under different `eval_metric_loss` parameters using this API. The vertical axis of visualized results shows eval_metric_loss parameter values and the horizontal axis shows pruning proportions of the corresponding models. `eval_metric_loss` (convolution sensitivity) is a model precision loss after the model is pruned according to a pruning rate.

### Parameters
> * **model** (paddlex.cv.models): Use a model loaded by PaddleX.
> * **sensitivities_file** (str): Calculated parameter sensitivity information file of model parameters on the validation set.
> * **save_dir**(str): Path where visualized results are saved. It is the current directory by default.


### Usage example
> Click to download the [model](https://bj.bcebos.com/paddlex/models/vegetables_mobilenet.tar.gz) and [sensitivities_file](https://bj.bcebos.com/paddlex/slim_prune/mobilenetv2.sensitivities) in the example
```
import paddlex as pdx
model = pdx.load_model('vegetables_mobilenet')
pdx.slim.visualize(model, 'mobilenetv2.sensitivities', save_dir='./')
# Visualized results are saved in . /sensitivities.png
```

## paddlex.transforms.visualize
> **Visualization of data preprocessing/enhancement process**
```
paddlex.transforms.visualize(dataset,
                             img_count=3,
                             save_dir='vdl_output')
```
Visualize intermediate results of data preprocessing/enhancement.
Intermediate results can be viewed using VisualDL:
1. VisualDL starting method: visualdl --logdir vdl_output/image_transforms --port 8001
2. Open https://0.0.0.0:8001 on the browser and click `[Sample Data-Image]` in the page.
    0.0.0.0 indicates local access. In case of remote services, change it to the corresponding machine IP address

### Parameters
> * **dataset** (paddlex.datasets): Dataset reader.
> * **img_count** (int): Number of images which require data preprocessing/enhancement. It is 3 by default.
> * **save_dir** (str): Path where logs are saved. It is 'vdl_output' by default.
